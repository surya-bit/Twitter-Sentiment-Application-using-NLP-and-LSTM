{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKaiwbk0HueQ",
        "outputId": "8f43427a-e2ce-4bb8-c9fa-2aad9ba0ad04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "8337/8337 [==============================] - 1777s 213ms/step - loss: 0.2037 - accuracy: 0.9072 - val_loss: 0.0994 - val_accuracy: 0.9373\n",
            "Epoch 2/2\n",
            "8337/8337 [==============================] - 1779s 213ms/step - loss: 0.0972 - accuracy: 0.9390 - val_loss: 0.0931 - val_accuracy: 0.9371\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7afd9770e2f0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"emotions.csv\")\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(data['text'], data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenize the texts\n",
        "max_features = 10000  # Number of words to consider as features\n",
        "max_len = 100  # Maximum length of texts\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
        "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
        "\n",
        "# Pad sequences to have consistent length\n",
        "train_data = pad_sequences(train_sequences, maxlen=max_len)\n",
        "test_data = pad_sequences(test_sequences, maxlen=max_len)\n",
        "\n",
        "# Convert labels to categorical\n",
        "num_classes = 6\n",
        "train_labels = to_categorical(train_labels, num_classes)\n",
        "test_labels = to_categorical(test_labels, num_classes)\n",
        "\n",
        "# Define the LSTM model\n",
        "# Building a very simple LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128, input_length=max_len))\n",
        "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "batch_size = 32\n",
        "epochs = 2\n",
        "model.fit(train_data, train_labels, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('final_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_qV1llcXHyY",
        "outputId": "a3976851-36bb-4fb5-af63-7512b9f7e1f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "scores = model.evaluate(test_data, test_labels)\n",
        "print(f\"Test Accuracy: {scores[1]*100:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vf0dh4gUINXL",
        "outputId": "31d86886-a745-4f49-c039-f590448db1b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2606/2606 [==============================] - 73s 28ms/step - loss: 0.0932 - accuracy: 0.9380\n",
            "Test Accuracy: 93.80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "predictions_prob = model.predict(test_data)\n",
        "predictions = np.argmax(predictions_prob, axis=1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1_WP9AAXnEu",
        "outputId": "5c171967-3aab-4de3-888b-8e8f76b66b5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2606/2606 [==============================] - 75s 29ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels = np.argmax(test_labels, axis=1)\n",
        "# Print classification report\n",
        "print(classification_report(true_labels, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_eeRyPQYSVJ",
        "outputId": "9a58f22f-392f-483a-d533-41da7ae880a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98     24201\n",
            "           1       0.94      0.97      0.95     28164\n",
            "           2       0.90      0.78      0.84      6929\n",
            "           3       0.96      0.92      0.94     11441\n",
            "           4       0.92      0.88      0.90      9594\n",
            "           5       0.74      0.94      0.83      3033\n",
            "\n",
            "    accuracy                           0.94     83362\n",
            "   macro avg       0.91      0.91      0.91     83362\n",
            "weighted avg       0.94      0.94      0.94     83362\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a single testing case\n",
        "test_case = [\"Just got into a car accident. Thankfully, everyone is okay, but I'm feeling shaken and anxious.\"]\n",
        "\n",
        "# Tokenize the test case\n",
        "test_case_sequence = tokenizer.texts_to_sequences(test_case)\n",
        "test_case_data = pad_sequences(test_case_sequence, maxlen=max_len)\n",
        "\n",
        "# Make prediction for the test case\n",
        "predicted_prob = model.predict(test_case_data)\n",
        "predicted_class = np.argmax(predicted_prob)\n",
        "\n",
        "# Map predicted class to emotion label\n",
        "emotion_labels = {0: \"sadness\", 1: \"joy\", 2: \"love\", 3: \"anger\", 4: \"fear\", 5: \"surprise\"}\n",
        "predicted_emotion = emotion_labels[predicted_class]\n",
        "\n",
        "# Print the predicted emotion\n",
        "print(\"Predicted emotion:\", predicted_emotion)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ssgu8IGFYvY9",
        "outputId": "30560fcc-51e1-400a-b7c5-e318663accee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 63ms/step\n",
            "Predicted emotion: fear\n"
          ]
        }
      ]
    }
  ]
}